{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "5871a523",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from autogluon.tabular import TabularDataset, TabularPredictor\n",
    "from autogluon.common.utils.utils import setup_outputdir\n",
    "from autogluon.core.utils.loaders import load_pkl\n",
    "from autogluon.core.utils.savers import save_pkl\n",
    "import os.path\n",
    "\n",
    "class MultilabelPredictor():\n",
    "    \"\"\" Tabular Predictor for predicting multiple columns in table.\n",
    "        Creates multiple TabularPredictor objects which you can also use individually.\n",
    "        You can access the TabularPredictor for a particular label via: `multilabel_predictor.get_predictor(label_i)`\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        labels : List[str]\n",
    "            The ith element of this list is the column (i.e. `label`) predicted by the ith TabularPredictor stored in this object.\n",
    "        path : str, default = None\n",
    "            Path to directory where models and intermediate outputs should be saved.\n",
    "            If unspecified, a time-stamped folder called \"AutogluonModels/ag-[TIMESTAMP]\" will be created in the working directory to store all models.\n",
    "            Note: To call `fit()` twice and save all results of each fit, you must specify different `path` locations or don't specify `path` at all.\n",
    "            Otherwise files from first `fit()` will be overwritten by second `fit()`.\n",
    "            Caution: when predicting many labels, this directory may grow large as it needs to store many TabularPredictors.\n",
    "        problem_types : List[str], default = None\n",
    "            The ith element is the `problem_type` for the ith TabularPredictor stored in this object.\n",
    "        eval_metrics : List[str], default = None\n",
    "            The ith element is the `eval_metric` for the ith TabularPredictor stored in this object.\n",
    "        consider_labels_correlation : bool, default = True\n",
    "            Whether the predictions of multiple labels should account for label correlations or predict each label independently of the others.\n",
    "            If True, the ordering of `labels` may affect resulting accuracy as each label is predicted conditional on the previous labels appearing earlier in this list (i.e. in an auto-regressive fashion).\n",
    "            Set to False if during inference you may want to individually use just the ith TabularPredictor without predicting all the other labels.\n",
    "        kwargs :\n",
    "            Arguments passed into the initialization of each TabularPredictor.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    multi_predictor_file = 'multilabel_predictor.pkl'\n",
    "\n",
    "    def __init__(self, labels, path=None, problem_types=None, eval_metrics=None, consider_labels_correlation=True, **kwargs):\n",
    "        if len(labels) < 2:\n",
    "            raise ValueError(\"MultilabelPredictor is only intended for predicting MULTIPLE labels (columns), use TabularPredictor for predicting one label (column).\")\n",
    "        if (problem_types is not None) and (len(problem_types) != len(labels)):\n",
    "            raise ValueError(\"If provided, `problem_types` must have same length as `labels`\")\n",
    "        if (eval_metrics is not None) and (len(eval_metrics) != len(labels)):\n",
    "            raise ValueError(\"If provided, `eval_metrics` must have same length as `labels`\")\n",
    "        self.path = setup_outputdir(path, warn_if_exist=False)\n",
    "        self.labels = labels\n",
    "        self.consider_labels_correlation = consider_labels_correlation\n",
    "        self.predictors = {}  # key = label, value = TabularPredictor or str path to the TabularPredictor for this label\n",
    "        if eval_metrics is None:\n",
    "            self.eval_metrics = {}\n",
    "        else:\n",
    "            self.eval_metrics = {labels[i] : eval_metrics[i] for i in range(len(labels))}\n",
    "        problem_type = None\n",
    "        eval_metric = None\n",
    "        for i in range(len(labels)):\n",
    "            label = labels[i]\n",
    "            path_i = self.path + \"Predictor_\" + label\n",
    "            if problem_types is not None:\n",
    "                problem_type = problem_types[i]\n",
    "            if eval_metrics is not None:\n",
    "                eval_metric = eval_metrics[i]\n",
    "            self.predictors[label] = TabularPredictor(label=label, problem_type=problem_type, eval_metric=eval_metric, path=path_i, **kwargs)\n",
    "\n",
    "    def fit(self, train_data, tuning_data=None, **kwargs):\n",
    "        \"\"\" Fits a separate TabularPredictor to predict each of the labels.\n",
    "\n",
    "            Parameters\n",
    "            ----------\n",
    "            train_data, tuning_data : str or autogluon.tabular.TabularDataset or pd.DataFrame\n",
    "                See documentation for `TabularPredictor.fit()`.\n",
    "            kwargs :\n",
    "                Arguments passed into the `fit()` call for each TabularPredictor.\n",
    "        \"\"\"\n",
    "        if isinstance(train_data, str):\n",
    "            train_data = TabularDataset(train_data)\n",
    "        if tuning_data is not None and isinstance(tuning_data, str):\n",
    "            tuning_data = TabularDataset(tuning_data)\n",
    "        train_data_og = train_data.copy()\n",
    "        if tuning_data is not None:\n",
    "            tuning_data_og = tuning_data.copy()\n",
    "        else:\n",
    "            tuning_data_og = None\n",
    "        save_metrics = len(self.eval_metrics) == 0\n",
    "        for i in range(len(self.labels)):\n",
    "            label = self.labels[i]\n",
    "            predictor = self.get_predictor(label)\n",
    "            if not self.consider_labels_correlation:\n",
    "                labels_to_drop = [l for l in self.labels if l != label]\n",
    "            else:\n",
    "                labels_to_drop = [self.labels[j] for j in range(i+1, len(self.labels))]\n",
    "            train_data = train_data_og.drop(labels_to_drop, axis=1)\n",
    "            if tuning_data is not None:\n",
    "                tuning_data = tuning_data_og.drop(labels_to_drop, axis=1)\n",
    "            print(f\"Fitting TabularPredictor for label: {label} ...\")\n",
    "            predictor.fit(train_data=train_data, tuning_data=tuning_data, **kwargs)\n",
    "            self.predictors[label] = predictor.path\n",
    "            if save_metrics:\n",
    "                self.eval_metrics[label] = predictor.eval_metric\n",
    "        self.save()\n",
    "\n",
    "    def predict(self, data, **kwargs):\n",
    "        \"\"\" Returns DataFrame with label columns containing predictions for each label.\n",
    "\n",
    "            Parameters\n",
    "            ----------\n",
    "            data : str or autogluon.tabular.TabularDataset or pd.DataFrame\n",
    "                Data to make predictions for. If label columns are present in this data, they will be ignored. See documentation for `TabularPredictor.predict()`.\n",
    "            kwargs :\n",
    "                Arguments passed into the predict() call for each TabularPredictor.\n",
    "        \"\"\"\n",
    "        return self._predict(data, as_proba=False, **kwargs)\n",
    "\n",
    "    def predict_proba(self, data, **kwargs):\n",
    "        \"\"\" Returns dict where each key is a label and the corresponding value is the `predict_proba()` output for just that label.\n",
    "\n",
    "            Parameters\n",
    "            ----------\n",
    "            data : str or autogluon.tabular.TabularDataset or pd.DataFrame\n",
    "                Data to make predictions for. See documentation for `TabularPredictor.predict()` and `TabularPredictor.predict_proba()`.\n",
    "            kwargs :\n",
    "                Arguments passed into the `predict_proba()` call for each TabularPredictor (also passed into a `predict()` call).\n",
    "        \"\"\"\n",
    "        return self._predict(data, as_proba=True, **kwargs)\n",
    "\n",
    "    def evaluate(self, data, **kwargs):\n",
    "        \"\"\" Returns dict where each key is a label and the corresponding value is the `evaluate()` output for just that label.\n",
    "\n",
    "            Parameters\n",
    "            ----------\n",
    "            data : str or autogluon.tabular.TabularDataset or pd.DataFrame\n",
    "                Data to evalate predictions of all labels for, must contain all labels as columns. See documentation for `TabularPredictor.evaluate()`.\n",
    "            kwargs :\n",
    "                Arguments passed into the `evaluate()` call for each TabularPredictor (also passed into the `predict()` call).\n",
    "        \"\"\"\n",
    "        data = self._get_data(data)\n",
    "        eval_dict = {}\n",
    "        for label in self.labels:\n",
    "            print(f\"Evaluating TabularPredictor for label: {label} ...\")\n",
    "            predictor = self.get_predictor(label)\n",
    "            eval_dict[label] = predictor.evaluate(data, **kwargs)\n",
    "            if self.consider_labels_correlation:\n",
    "                data[label] = predictor.predict(data, **kwargs)\n",
    "        return eval_dict\n",
    "\n",
    "    def save(self):\n",
    "        \"\"\" Save MultilabelPredictor to disk. \"\"\"\n",
    "        for label in self.labels:\n",
    "            if not isinstance(self.predictors[label], str):\n",
    "                self.predictors[label] = self.predictors[label].path\n",
    "        save_pkl.save(path=self.path+self.multi_predictor_file, object=self)\n",
    "        print(f\"MultilabelPredictor saved to disk. Load with: MultilabelPredictor.load('{self.path}')\")\n",
    "\n",
    "    @classmethod\n",
    "    def load(cls, path):\n",
    "        \"\"\" Load MultilabelPredictor from disk `path` previously specified when creating this MultilabelPredictor. \"\"\"\n",
    "        path = os.path.expanduser(path)\n",
    "        if path[-1] != os.path.sep:\n",
    "            path = path + os.path.sep\n",
    "        return load_pkl.load(path=path+cls.multi_predictor_file)\n",
    "\n",
    "    def get_predictor(self, label):\n",
    "        \"\"\" Returns TabularPredictor which is used to predict this label. \"\"\"\n",
    "        predictor = self.predictors[label]\n",
    "        if isinstance(predictor, str):\n",
    "            return TabularPredictor.load(path=predictor)\n",
    "        return predictor\n",
    "\n",
    "    def _get_data(self, data):\n",
    "        if isinstance(data, str):\n",
    "            return TabularDataset(data)\n",
    "        return data.copy()\n",
    "\n",
    "    def _predict(self, data, as_proba=False, **kwargs):\n",
    "        data = self._get_data(data)\n",
    "        if as_proba:\n",
    "            predproba_dict = {}\n",
    "        for label in self.labels:\n",
    "            print(f\"Predicting with TabularPredictor for label: {label} ...\")\n",
    "            predictor = self.get_predictor(label)\n",
    "            if as_proba:\n",
    "                predproba_dict[label] = predictor.predict_proba(data, as_multiclass=True, **kwargs)\n",
    "            data[label] = predictor.predict(data, **kwargs)\n",
    "        if not as_proba:\n",
    "            return data[self.labels]\n",
    "        else:\n",
    "            return predproba_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "793dbc81",
   "metadata": {},
   "source": [
    "Below is multimodal\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "c153b2ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary of class variable: \n",
      " count    1.0\n",
      "mean     1.0\n",
      "std      NaN\n",
      "min      1.0\n",
      "25%      1.0\n",
      "50%      1.0\n",
      "75%      1.0\n",
      "max      1.0\n",
      "Name: Win or Loss for Warriors, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "feature_columns = ['Home Team', 'Away Team', 'Win or Loss for Celtics', 'Win or Loss for Warriors']\n",
    "label = 'Win or Loss for Warriors'\n",
    "print(\"Summary of class variable: \\n\", train_data[label].describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af473404",
   "metadata": {},
   "source": [
    "Below is non modal\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "648efc2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loaded data from: C:/Users/Ali-Akber/Desktop/basketballDataset.csv | Columns = 7 / 7 | Rows = 45 -> 45\n"
     ]
    }
   ],
   "source": [
    "train_data = TabularDataset(\"C:/Users/Ali-Akber/Desktop/basketballDataset.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "a9a5b428",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Home Team</th>\n",
       "      <th>Away Team</th>\n",
       "      <th>Win or Loss for Celtics</th>\n",
       "      <th>Win or Loss for Warriors</th>\n",
       "      <th>Celtics score</th>\n",
       "      <th>Warriors score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>15</td>\n",
       "      <td>Celtics</td>\n",
       "      <td>Warriors</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>95</td>\n",
       "      <td>96</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Date Home Team Away Team  Win or Loss for Celtics  \\\n",
       "30    15   Celtics  Warriors                        2   \n",
       "\n",
       "    Win or Loss for Warriors  Celtics score  Warriors score  \n",
       "30                         1             95              96  "
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data = train_data.sample(random_state=0)\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "be8b748e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary of class variable: \n",
      " count    45.000000\n",
      "mean      1.511111\n",
      "std       0.505525\n",
      "min       1.000000\n",
      "25%       1.000000\n",
      "50%       2.000000\n",
      "75%       2.000000\n",
      "max       2.000000\n",
      "Name: Win or Loss for Warriors, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "labels = ['Win or Loss for Celtics','Win or Loss for Warriors','Celtics score', 'Warriors score']\n",
    "problem_types = ['binary','binary','regression', 'regression']  # type of each prediction problem\n",
    "save_path = 'agModels-predictEducationClass'\n",
    "time_limit = 20\n",
    "print(\"Summary of class variable: \\n\", train_data[label].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "2e4c97dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: path already exists! This predictor may overwrite an existing predictor! path=\"agModels-predictEducationClass\\Predictor_Win or Loss for Celtics\"\n",
      "Warning: path already exists! This predictor may overwrite an existing predictor! path=\"agModels-predictEducationClass\\Predictor_Win or Loss for Warriors\"\n",
      "Warning: path already exists! This predictor may overwrite an existing predictor! path=\"agModels-predictEducationClass\\Predictor_Celtics score\"\n",
      "Warning: path already exists! This predictor may overwrite an existing predictor! path=\"agModels-predictEducationClass\\Predictor_Warriors score\"\n",
      "Beginning AutoGluon training ... Time limit = 20s\n",
      "AutoGluon will save models to \"agModels-predictEducationClass\\Predictor_Win or Loss for Celtics\\\"\n",
      "AutoGluon Version:  0.4.2\n",
      "Python Version:     3.7.13\n",
      "Operating System:   Windows\n",
      "Train Data Rows:    45\n",
      "Train Data Columns: 3\n",
      "Label Column: Win or Loss for Celtics\n",
      "Preprocessing data ...\n",
      "Selected class <--> label mapping:  class 1 = 2, class 0 = 1\n",
      "\tNote: For your binary classification, AutoGluon arbitrarily selected which label-value represents positive (2) vs negative (1) class.\n",
      "\tTo explicitly set the positive_class, either rename classes to 1 and 0, or specify positive_class in Predictor init.\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    9253.26 MB\n",
      "\tTrain Data (Original)  Memory Usage: 0.01 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\t\t\tNote: Converting 2 features to boolean dtype as they only contain 2 unique values.\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('int', [])    : 1 | ['Date']\n",
      "\t\t('object', []) : 2 | ['Home Team', 'Away Team']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('int', [])       : 1 | ['Date']\n",
      "\t\t('int', ['bool']) : 2 | ['Home Team', 'Away Team']\n",
      "\t0.0s = Fit runtime\n",
      "\t3 features in original data used to generate 3 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.0 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.04s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'accuracy'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Automatically generating train/validation split with holdout_frac=0.2, Train Rows: 36, Val Rows: 9\n",
      "Fitting 13 L1 models ...\n",
      "Fitting model: KNeighborsUnif ... Training model for up to 19.96s of the 19.96s of remaining time.\n",
      "\t0.6667\t = Validation score   (accuracy)\n",
      "\t0.0s\t = Training   runtime\n",
      "\t0.11s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist ... Training model for up to 19.84s of the 19.84s of remaining time.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting TabularPredictor for label: Win or Loss for Celtics ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t0.6667\t = Validation score   (accuracy)\n",
      "\t0.0s\t = Training   runtime\n",
      "\t0.12s\t = Validation runtime\n",
      "Fitting model: LightGBMXT ... Training model for up to 19.7s of the 19.7s of remaining time.\n",
      "\t0.4444\t = Validation score   (accuracy)\n",
      "\t0.08s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: LightGBM ... Training model for up to 19.61s of the 19.61s of remaining time.\n",
      "\t0.4444\t = Validation score   (accuracy)\n",
      "\t0.09s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: RandomForestGini ... Training model for up to 19.51s of the 19.51s of remaining time.\n",
      "\t0.6667\t = Validation score   (accuracy)\n",
      "\t0.46s\t = Training   runtime\n",
      "\t0.11s\t = Validation runtime\n",
      "Fitting model: RandomForestEntr ... Training model for up to 18.92s of the 18.92s of remaining time.\n",
      "\t0.6667\t = Validation score   (accuracy)\n",
      "\t0.41s\t = Training   runtime\n",
      "\t0.11s\t = Validation runtime\n",
      "Fitting model: CatBoost ... Training model for up to 18.38s of the 18.38s of remaining time.\n",
      "\t0.6667\t = Validation score   (accuracy)\n",
      "\t0.21s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: ExtraTreesGini ... Training model for up to 18.16s of the 18.16s of remaining time.\n",
      "\t0.6667\t = Validation score   (accuracy)\n",
      "\t0.41s\t = Training   runtime\n",
      "\t0.11s\t = Validation runtime\n",
      "Fitting model: ExtraTreesEntr ... Training model for up to 17.62s of the 17.62s of remaining time.\n",
      "\t0.6667\t = Validation score   (accuracy)\n",
      "\t0.42s\t = Training   runtime\n",
      "\t0.11s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI ... Training model for up to 17.06s of the 17.06s of remaining time.\n",
      "No improvement since epoch 8: early stopping\n",
      "\t0.7778\t = Validation score   (accuracy)\n",
      "\t0.35s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: XGBoost ... Training model for up to 16.69s of the 16.69s of remaining time.\n",
      "\t0.7778\t = Validation score   (accuracy)\n",
      "\t0.09s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch ... Training model for up to 16.59s of the 16.59s of remaining time.\n",
      "\t0.6667\t = Validation score   (accuracy)\n",
      "\t0.27s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: LightGBMLarge ... Training model for up to 16.31s of the 16.3s of remaining time.\n",
      "\t0.7778\t = Validation score   (accuracy)\n",
      "\t0.09s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ... Training model for up to 19.96s of the 15.34s of remaining time.\n",
      "\t0.7778\t = Validation score   (accuracy)\n",
      "\t0.27s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 4.95s ... Best model: \"WeightedEnsemble_L2\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"agModels-predictEducationClass\\Predictor_Win or Loss for Celtics\\\")\n",
      "Beginning AutoGluon training ... Time limit = 20s\n",
      "AutoGluon will save models to \"agModels-predictEducationClass\\Predictor_Win or Loss for Warriors\\\"\n",
      "AutoGluon Version:  0.4.2\n",
      "Python Version:     3.7.13\n",
      "Operating System:   Windows\n",
      "Train Data Rows:    45\n",
      "Train Data Columns: 4\n",
      "Label Column: Win or Loss for Warriors\n",
      "Preprocessing data ...\n",
      "Selected class <--> label mapping:  class 1 = 2, class 0 = 1\n",
      "\tNote: For your binary classification, AutoGluon arbitrarily selected which label-value represents positive (2) vs negative (1) class.\n",
      "\tTo explicitly set the positive_class, either rename classes to 1 and 0, or specify positive_class in Predictor init.\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    9228.27 MB\n",
      "\tTrain Data (Original)  Memory Usage: 0.01 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\t\t\tNote: Converting 3 features to boolean dtype as they only contain 2 unique values.\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('int', [])    : 2 | ['Date', 'Win or Loss for Celtics']\n",
      "\t\t('object', []) : 2 | ['Home Team', 'Away Team']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('int', [])       : 1 | ['Date']\n",
      "\t\t('int', ['bool']) : 3 | ['Home Team', 'Away Team', 'Win or Loss for Celtics']\n",
      "\t0.0s = Fit runtime\n",
      "\t4 features in original data used to generate 4 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.0 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.03s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'accuracy'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Automatically generating train/validation split with holdout_frac=0.2, Train Rows: 36, Val Rows: 9\n",
      "Fitting 13 L1 models ...\n",
      "Fitting model: KNeighborsUnif ... Training model for up to 19.97s of the 19.97s of remaining time.\n",
      "\t0.6667\t = Validation score   (accuracy)\n",
      "\t0.0s\t = Training   runtime\n",
      "\t0.12s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist ... Training model for up to 19.84s of the 19.84s of remaining time.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting TabularPredictor for label: Win or Loss for Warriors ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t0.3333\t = Validation score   (accuracy)\n",
      "\t0.0s\t = Training   runtime\n",
      "\t0.12s\t = Validation runtime\n",
      "Fitting model: LightGBMXT ... Training model for up to 19.72s of the 19.72s of remaining time.\n",
      "\t0.5556\t = Validation score   (accuracy)\n",
      "\t0.07s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: LightGBM ... Training model for up to 19.65s of the 19.64s of remaining time.\n",
      "\t0.5556\t = Validation score   (accuracy)\n",
      "\t0.09s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: RandomForestGini ... Training model for up to 19.55s of the 19.55s of remaining time.\n",
      "\t1.0\t = Validation score   (accuracy)\n",
      "\t0.46s\t = Training   runtime\n",
      "\t0.12s\t = Validation runtime\n",
      "Fitting model: RandomForestEntr ... Training model for up to 18.95s of the 18.95s of remaining time.\n",
      "\t1.0\t = Validation score   (accuracy)\n",
      "\t0.41s\t = Training   runtime\n",
      "\t0.11s\t = Validation runtime\n",
      "Fitting model: CatBoost ... Training model for up to 18.42s of the 18.42s of remaining time.\n",
      "\t0.8889\t = Validation score   (accuracy)\n",
      "\t0.19s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: ExtraTreesGini ... Training model for up to 18.23s of the 18.23s of remaining time.\n",
      "\t1.0\t = Validation score   (accuracy)\n",
      "\t0.41s\t = Training   runtime\n",
      "\t0.12s\t = Validation runtime\n",
      "Fitting model: ExtraTreesEntr ... Training model for up to 17.68s of the 17.68s of remaining time.\n",
      "\t1.0\t = Validation score   (accuracy)\n",
      "\t0.41s\t = Training   runtime\n",
      "\t0.11s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI ... Training model for up to 17.14s of the 17.13s of remaining time.\n",
      "No improvement since epoch 2: early stopping\n",
      "\t1.0\t = Validation score   (accuracy)\n",
      "\t0.29s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: XGBoost ... Training model for up to 16.82s of the 16.82s of remaining time.\n",
      "\t1.0\t = Validation score   (accuracy)\n",
      "\t0.07s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch ... Training model for up to 16.74s of the 16.74s of remaining time.\n",
      "\t1.0\t = Validation score   (accuracy)\n",
      "\t0.24s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: LightGBMLarge ... Training model for up to 16.49s of the 16.49s of remaining time.\n",
      "\t1.0\t = Validation score   (accuracy)\n",
      "\t0.09s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ... Training model for up to 19.97s of the 15.54s of remaining time.\n",
      "\t1.0\t = Validation score   (accuracy)\n",
      "\t0.25s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 4.74s ... Best model: \"WeightedEnsemble_L2\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"agModels-predictEducationClass\\Predictor_Win or Loss for Warriors\\\")\n",
      "Beginning AutoGluon training ... Time limit = 20s\n",
      "AutoGluon will save models to \"agModels-predictEducationClass\\Predictor_Celtics score\\\"\n",
      "AutoGluon Version:  0.4.2\n",
      "Python Version:     3.7.13\n",
      "Operating System:   Windows\n",
      "Train Data Rows:    45\n",
      "Train Data Columns: 5\n",
      "Label Column: Celtics score\n",
      "Preprocessing data ...\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    9249.17 MB\n",
      "\tTrain Data (Original)  Memory Usage: 0.01 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\t\t\tNote: Converting 4 features to boolean dtype as they only contain 2 unique values.\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('int', [])    : 3 | ['Date', 'Win or Loss for Celtics', 'Win or Loss for Warriors']\n",
      "\t\t('object', []) : 2 | ['Home Team', 'Away Team']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('int', [])       : 1 | ['Date']\n",
      "\t\t('int', ['bool']) : 4 | ['Home Team', 'Away Team', 'Win or Loss for Celtics', 'Win or Loss for Warriors']\n",
      "\t0.0s = Fit runtime\n",
      "\t5 features in original data used to generate 5 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.0 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.03s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'root_mean_squared_error'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Automatically generating train/validation split with holdout_frac=0.2, Train Rows: 36, Val Rows: 9\n",
      "Fitting 11 L1 models ...\n",
      "Fitting model: KNeighborsUnif ... Training model for up to 19.97s of the 19.96s of remaining time.\n",
      "\t-14.0689\t = Validation score   (root_mean_squared_error)\n",
      "\t0.0s\t = Training   runtime\n",
      "\t0.11s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist ... Training model for up to 19.85s of the 19.84s of remaining time.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting TabularPredictor for label: Celtics score ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t-14.2033\t = Validation score   (root_mean_squared_error)\n",
      "\t0.0s\t = Training   runtime\n",
      "\t0.12s\t = Validation runtime\n",
      "Fitting model: LightGBMXT ... Training model for up to 19.72s of the 19.72s of remaining time.\n",
      "\t-12.9238\t = Validation score   (root_mean_squared_error)\n",
      "\t0.07s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: LightGBM ... Training model for up to 19.64s of the 19.64s of remaining time.\n",
      "\t-12.9238\t = Validation score   (root_mean_squared_error)\n",
      "\t0.09s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: RandomForestMSE ... Training model for up to 19.55s of the 19.55s of remaining time.\n",
      "\t-14.2497\t = Validation score   (root_mean_squared_error)\n",
      "\t0.34s\t = Training   runtime\n",
      "\t0.11s\t = Validation runtime\n",
      "Fitting model: CatBoost ... Training model for up to 19.09s of the 19.09s of remaining time.\n",
      "\t-12.4672\t = Validation score   (root_mean_squared_error)\n",
      "\t0.15s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: ExtraTreesMSE ... Training model for up to 18.93s of the 18.93s of remaining time.\n",
      "\t-14.0932\t = Validation score   (root_mean_squared_error)\n",
      "\t0.41s\t = Training   runtime\n",
      "\t0.12s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI ... Training model for up to 18.38s of the 18.38s of remaining time.\n",
      "No improvement since epoch 7: early stopping\n",
      "\t-12.1141\t = Validation score   (root_mean_squared_error)\n",
      "\t0.35s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: XGBoost ... Training model for up to 18.01s of the 18.01s of remaining time.\n",
      "\t-13.1305\t = Validation score   (root_mean_squared_error)\n",
      "\t0.16s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch ... Training model for up to 17.84s of the 17.84s of remaining time.\n",
      "\t-12.9249\t = Validation score   (root_mean_squared_error)\n",
      "\t0.22s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: LightGBMLarge ... Training model for up to 17.61s of the 17.61s of remaining time.\n",
      "\t-11.9474\t = Validation score   (root_mean_squared_error)\n",
      "\t0.1s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ... Training model for up to 19.97s of the 16.87s of remaining time.\n",
      "\t-11.9367\t = Validation score   (root_mean_squared_error)\n",
      "\t0.25s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 3.4s ... Best model: \"WeightedEnsemble_L2\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"agModels-predictEducationClass\\Predictor_Celtics score\\\")\n",
      "Beginning AutoGluon training ... Time limit = 20s\n",
      "AutoGluon will save models to \"agModels-predictEducationClass\\Predictor_Warriors score\\\"\n",
      "AutoGluon Version:  0.4.2\n",
      "Python Version:     3.7.13\n",
      "Operating System:   Windows\n",
      "Train Data Rows:    45\n",
      "Train Data Columns: 6\n",
      "Label Column: Warriors score\n",
      "Preprocessing data ...\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    9247.87 MB\n",
      "\tTrain Data (Original)  Memory Usage: 0.01 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\t\t\tNote: Converting 4 features to boolean dtype as they only contain 2 unique values.\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('int', [])    : 4 | ['Date', 'Win or Loss for Celtics', 'Win or Loss for Warriors', 'Celtics score']\n",
      "\t\t('object', []) : 2 | ['Home Team', 'Away Team']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('int', [])       : 2 | ['Date', 'Celtics score']\n",
      "\t\t('int', ['bool']) : 4 | ['Home Team', 'Away Team', 'Win or Loss for Celtics', 'Win or Loss for Warriors']\n",
      "\t0.0s = Fit runtime\n",
      "\t6 features in original data used to generate 6 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.0 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.03s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'root_mean_squared_error'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Automatically generating train/validation split with holdout_frac=0.2, Train Rows: 36, Val Rows: 9\n",
      "Fitting 11 L1 models ...\n",
      "Fitting model: KNeighborsUnif ... Training model for up to 19.97s of the 19.96s of remaining time.\n",
      "\t-12.0215\t = Validation score   (root_mean_squared_error)\n",
      "\t0.0s\t = Training   runtime\n",
      "\t0.12s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist ... Training model for up to 19.84s of the 19.84s of remaining time.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting TabularPredictor for label: Warriors score ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t-12.0528\t = Validation score   (root_mean_squared_error)\n",
      "\t0.0s\t = Training   runtime\n",
      "\t0.12s\t = Validation runtime\n",
      "Fitting model: LightGBMXT ... Training model for up to 19.72s of the 19.72s of remaining time.\n",
      "\t-11.8278\t = Validation score   (root_mean_squared_error)\n",
      "\t0.07s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: LightGBM ... Training model for up to 19.64s of the 19.64s of remaining time.\n",
      "\t-11.8278\t = Validation score   (root_mean_squared_error)\n",
      "\t0.09s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: RandomForestMSE ... Training model for up to 19.54s of the 19.54s of remaining time.\n",
      "\t-9.8754\t = Validation score   (root_mean_squared_error)\n",
      "\t0.43s\t = Training   runtime\n",
      "\t0.13s\t = Validation runtime\n",
      "Fitting model: CatBoost ... Training model for up to 18.97s of the 18.97s of remaining time.\n",
      "\t-10.4349\t = Validation score   (root_mean_squared_error)\n",
      "\t0.21s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: ExtraTreesMSE ... Training model for up to 18.75s of the 18.75s of remaining time.\n",
      "\t-10.0879\t = Validation score   (root_mean_squared_error)\n",
      "\t0.41s\t = Training   runtime\n",
      "\t0.11s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI ... Training model for up to 18.22s of the 18.22s of remaining time.\n",
      "\t-10.7805\t = Validation score   (root_mean_squared_error)\n",
      "\t0.37s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: XGBoost ... Training model for up to 17.84s of the 17.83s of remaining time.\n",
      "\t-10.4974\t = Validation score   (root_mean_squared_error)\n",
      "\t0.15s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch ... Training model for up to 17.68s of the 17.67s of remaining time.\n",
      "\t-8.1304\t = Validation score   (root_mean_squared_error)\n",
      "\t0.47s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: LightGBMLarge ... Training model for up to 17.2s of the 17.2s of remaining time.\n",
      "\t-9.4604\t = Validation score   (root_mean_squared_error)\n",
      "\t0.11s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ... Training model for up to 19.97s of the 16.48s of remaining time.\n",
      "\t-8.1108\t = Validation score   (root_mean_squared_error)\n",
      "\t0.26s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 3.79s ... Best model: \"WeightedEnsemble_L2\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"agModels-predictEducationClass\\Predictor_Warriors score\\\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MultilabelPredictor saved to disk. Load with: MultilabelPredictor.load('agModels-predictEducationClass\\')\n"
     ]
    }
   ],
   "source": [
    "multi_predictor = MultilabelPredictor(labels=labels, problem_types=problem_types, path=save_path)\n",
    "multi_predictor.fit(train_data, time_limit=time_limit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "8a867b35",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loaded data from: C:/Users/Ali-Akber/Desktop/bbtest.csv | Columns = 3 / 3 | Rows = 7 -> 7\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Home Team</th>\n",
       "      <th>Away Team</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>46</td>\n",
       "      <td>Warriors</td>\n",
       "      <td>Celtics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>47</td>\n",
       "      <td>Warriors</td>\n",
       "      <td>Celtics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>48</td>\n",
       "      <td>Celtics</td>\n",
       "      <td>Warriors</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>49</td>\n",
       "      <td>Celtics</td>\n",
       "      <td>Warriors</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>50</td>\n",
       "      <td>Warriors</td>\n",
       "      <td>Celtics</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Date Home Team Away Team\n",
       "0    46  Warriors   Celtics\n",
       "1    47  Warriors   Celtics\n",
       "2    48   Celtics  Warriors\n",
       "3    49   Celtics  Warriors\n",
       "4    50  Warriors   Celtics"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data = TabularDataset(\"C:/Users/Ali-Akber/Desktop/bbtest.csv\")\n",
    "test_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "413590cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting with TabularPredictor for label: Win or Loss for Celtics ...\n",
      "Predicting with TabularPredictor for label: Win or Loss for Warriors ...\n",
      "Predicting with TabularPredictor for label: Celtics score ...\n",
      "Predicting with TabularPredictor for label: Warriors score ...\n",
      "Predictions:  \n",
      "    Win or Loss for Celtics  Win or Loss for Warriors  Celtics score  \\\n",
      "0                        1                         2     109.553680   \n",
      "1                        1                         2     109.564957   \n",
      "2                        1                         2     110.135147   \n",
      "3                        1                         2     110.169891   \n",
      "4                        1                         2     109.625031   \n",
      "5                        1                         2     110.240417   \n",
      "6                        1                         2     109.679245   \n",
      "\n",
      "   Warriors score  \n",
      "0       99.541359  \n",
      "1       99.490753  \n",
      "2      105.684631  \n",
      "3      105.792542  \n",
      "4       99.368919  \n",
      "5      105.989136  \n",
      "6       99.329903  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Home Team</th>\n",
       "      <th>Away Team</th>\n",
       "      <th>Win or Loss for Celtics</th>\n",
       "      <th>Win or Loss for Warriors</th>\n",
       "      <th>Celtics score</th>\n",
       "      <th>Warriors score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>46</td>\n",
       "      <td>Warriors</td>\n",
       "      <td>Celtics</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>109.553680</td>\n",
       "      <td>99.541359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>47</td>\n",
       "      <td>Warriors</td>\n",
       "      <td>Celtics</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>109.564957</td>\n",
       "      <td>99.490753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>48</td>\n",
       "      <td>Celtics</td>\n",
       "      <td>Warriors</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>110.135147</td>\n",
       "      <td>105.684631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>49</td>\n",
       "      <td>Celtics</td>\n",
       "      <td>Warriors</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>110.169891</td>\n",
       "      <td>105.792542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>50</td>\n",
       "      <td>Warriors</td>\n",
       "      <td>Celtics</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>109.625031</td>\n",
       "      <td>99.368919</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Date Home Team Away Team  Win or Loss for Celtics  \\\n",
       "0    46  Warriors   Celtics                        1   \n",
       "1    47  Warriors   Celtics                        1   \n",
       "2    48   Celtics  Warriors                        1   \n",
       "3    49   Celtics  Warriors                        1   \n",
       "4    50  Warriors   Celtics                        1   \n",
       "\n",
       "   Win or Loss for Warriors  Celtics score  Warriors score  \n",
       "0                         2     109.553680       99.541359  \n",
       "1                         2     109.564957       99.490753  \n",
       "2                         2     110.135147      105.684631  \n",
       "3                         2     110.169891      105.792542  \n",
       "4                         2     109.625031       99.368919  "
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = multi_predictor.predict(test_data)\n",
    "print(\"Predictions:  \\n\", y_pred)\n",
    "import pandas as pd\n",
    "sub = pd.read_csv(\"C:/Users/Ali-Akber/Desktop/submission.csv\")\n",
    "sub[labels] = y_pred\n",
    "sub.to_csv(\"C:/Users/Ali-Akber/Desktop/submission.csv\", index=False)\n",
    "sub.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fastai",
   "language": "python",
   "name": "fastai"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
